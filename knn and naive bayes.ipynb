{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29a77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def naive_bayes(x_train, y_train):\n",
    "  \"\"\"\n",
    "  Implement the Naive Bayes algorithm from scratch.\n",
    "\n",
    "  Args:\n",
    "    x_train: The features of the training data.\n",
    "    y_train: The labels of the training data.\n",
    "\n",
    "  Returns:\n",
    "    A function that predicts the label of a new data point.\n",
    "  \"\"\"\n",
    "\n",
    "  # Calculate the prior probabilities of each class.\n",
    "  prior_probs = np.array([np.sum(y_train == i) / len(y_train) for i in np.unique(y_train)])\n",
    "\n",
    "  # Calculate the conditional probabilities of each feature given each class.\n",
    "  conditional_probs = []\n",
    "  for i in range(len(x_train[0])):\n",
    "    conditional_probs.append(np.array([np.sum(x_train[:, i] == j) / len(y_train == i) for j in np.unique(x_train[:, i])]) for i in range(len(x_train[0])))\n",
    "\n",
    "  # Define a function that predicts the label of a new data point.\n",
    "  def predict(x_new):\n",
    "    prob_per_class = []\n",
    "    for i in range(len(y_train)):\n",
    "      prob_per_class.append(prior_probs[i] * np.prod(conditional_probs[i][x_new]))\n",
    "    return np.argmax(prob_per_class)\n",
    "\n",
    "  return predict\n",
    "\n",
    "def k_nearest_neighbors(x_train, y_train, k):\n",
    "  \n",
    " # Implement the K-Nearest Neighbours algorithm from scratch.\n",
    "\n",
    "  #Args:\n",
    "    #x_train: The features of the training data.\n",
    "    #y_train: The labels of the training data.\n",
    "    #k: The number of nearest neighbors to consider.\n",
    "\n",
    " # Returns:\n",
    "  #  A function that predicts the label of a new data point.\n",
    "  \n",
    "\n",
    "  # Calculate the distances between the new data point and all the training data points.\n",
    "  distances = np.linalg.norm(x_train - x_new, axis=1)\n",
    "\n",
    "  # Find the k nearest neighbors.\n",
    "  nearest_neighbors = np.argsort(distances)[:k]\n",
    "\n",
    "  # Return the majority label of the k nearest neighbors.\n",
    "  return np.mode(y_train[nearest_neighbors])\n",
    "\n",
    "def main():\n",
    "  # Load the Iris dataset.\n",
    "  df = pd.read_csv('gender_submission.csv')\n",
    "  predictions = df['Survived']\n",
    "\n",
    "  print(predictions)\n",
    "  df_train = pd.read_csv('train.csv')\n",
    "  df_test = pd.read_csv('test.csv')\n",
    "\n",
    "  x_train, x_test, y_train, y_test = train_test_split(df_train.drop('Survived', axis=1), df_train['Survived'], test_size=0.25)\n",
    "\n",
    "# Train a machine learning model\n",
    " # model = ...\n",
    "\n",
    "# Make predictions on the test set\n",
    " # predictions = model.predict(x_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    " # accuracy = np.mean(predictions == y_test)\n",
    "\n",
    " # print('Accuracy:', accuracy)\n",
    "\n",
    "  # Split the data into training and test sets.\n",
    " # x_train, x_test, y_train, y_test = train_test_split(df.drop('Survived', axis=1), df['Survived'], test_size=0.25)\n",
    "\n",
    "  # Train the Naive Bayes classifier.\n",
    "  nb_clf = naive_bayes(x_train, y_train)\n",
    "\n",
    "  # Train the K-Nearest Neighbours classifier.\n",
    "  knn_clf = k_nearest_neighbors(x_train, y_train, 5)\n",
    "\n",
    "  # Make predictions on the test set.\n",
    "  nb_predictions = nb_clf(x_test)\n",
    "  knn_predictions = knn_clf(x_test)\n",
    "\n",
    "  # Evaluate the accuracy of the classifiers.\n",
    "  nb_accuracy = np.mean(nb_predictions == y_test)\n",
    "  knn_accuracy = np.mean(knn_predictions == y_test)\n",
    "\n",
    "  # Print the accuracy of the classifiers.\n",
    "  print('Naive Bayes accuracy:', nb_accuracy)\n",
    "  print('K-Nearest Neighbours accuracy:', knn_accuracy)\n",
    "\n",
    "  # Plot the decision boundaries of the classifiers.\n",
    "  plt.figure()\n",
    "  plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, cmap='tab10')\n",
    "  plt.plot(x_test)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73904a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd900147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa377ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
